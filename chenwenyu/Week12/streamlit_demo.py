import streamlit as st

from agents.mcp.server import MCPServerSse
import asyncio
from agents import Agent, Runner, AsyncOpenAI, OpenAIChatCompletionsModel, SQLiteSession
from openai.types.responses import ResponseTextDeltaEvent
from agents.mcp import MCPServer
from agents import set_default_openai_api, set_tracing_disabled
set_default_openai_api("chat_completions")
set_tracing_disabled(True)

st.set_page_config(page_title="ä¼ä¸šèŒèƒ½æœºå™¨äºº")
session = SQLiteSession("conversation_123")

with st.sidebar:
    st.title('èŒèƒ½AI+æ™ºèƒ½é—®ç­”')
    if 'API_TOKEN' in st.session_state and len(st.session_state['API_TOKEN']) > 1:
        st.success('API Tokenå·²ç»é…ç½®', icon='âœ…')
        key = st.session_state['API_TOKEN']
    else:
        key = ""

    key = st.text_input('è¾“å…¥Token:', type='password', value=key)

    st.session_state['API_TOKEN'] = key
    model_name = st.selectbox("é€‰æ‹©æ¨¡å‹", ["qwen-flash", "qwen-max"])
    use_tool = st.checkbox("ä½¿ç”¨å·¥å…·")


# åˆå§‹åŒ–çš„å¯¹è¯
if "messages" not in st.session_state.keys():
    st.session_state.messages = [
        {"role": "assistant", "content": "ä½ å¥½ï¼Œæˆ‘æ˜¯ä¼ä¸šèŒèƒ½åŠ©æ‰‹ï¼Œå¯ä»¥AIå¯¹è¯ ä¹Ÿ å¯ä»¥è°ƒç”¨å†…éƒ¨å·¥å…·ã€‚"}]

for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.write(message["content"])


def clear_chat_history():
    st.session_state.messages = [
        {"role": "assistant", "content": "ä½ å¥½ï¼Œæˆ‘æ˜¯ä¼ä¸šèŒèƒ½åŠ©æ‰‹ï¼Œå¯ä»¥AIå¯¹è¯ ä¹Ÿ å¯ä»¥è°ƒç”¨å†…éƒ¨å·¥å…·ã€‚"}]

    global session
    session = SQLiteSession("conversation_123")


st.sidebar.button('æ¸…ç©ºèŠå¤©', on_click=clear_chat_history)

def detect_tool_and_params(prompt):
    """æ£€æµ‹ç”¨æˆ·è¾“å…¥åº”è¯¥è°ƒç”¨å“ªä¸ªå·¥å…·ä»¥åŠå‚æ•°"""
    prompt_lower = prompt.lower()
    
    # å·¥å…·æ˜ å°„é…ç½®
    tool_mappings = [
        {
            "keywords": ["æ–°é—»", "å¤´æ¡", "çƒ­ç‚¹", "èµ„è®¯", "ä»Šæ—¥è¦é—»", "æœ€æ–°æ¶ˆæ¯"],
            "tools": [
                {"name": "get_today_daily_news", "params": {}},
                {"name": "get_douyin_hot_news", "params": {}},
                {"name": "get_toutiao_hot_news", "params": {}},
                {"name": "get_sports_news", "params": {}},
                {"name": "get_github_hot_news", "params": {}}
            ]
        },
        {
            "keywords": ["å¤©æ°”", "æ°”æ¸©", "æ¸©åº¦", "ä¸‹é›¨", "æ™´å¤©", "æ°”è±¡"],
            "tools": [
                {
                    "name": "get_city_weather", 
                    "params": {"city_name": "beijing"},  # é»˜è®¤å€¼
                    "param_extractor": lambda p: extract_city_name(p)  # åŸå¸‚åæå–å‡½æ•°
                }
            ]
        },
        {
            "keywords": ["æ±‡ç‡", "å…‘æ¢", "ç¾å…ƒ", "äººæ°‘å¸", "è´§å¸", "æ¢ç®—"],
            "tools": [
                {
                    "name": "get_rate_transform",
                    "params": {"source_coin": "USD", "aim_coin": "CNY", "money": 100},
                    "param_extractor": lambda p: extract_currency_params(p)
                }
            ]
        },
        {
            "keywords": ["åˆ†ç±»", "å½’ç±»", "æ–‡æœ¬åˆ†ç±»", "ç±»åˆ«"],
            "tools": [
                {
                    "name": "text_classification",
                    "params": {"text": ""},
                    "param_extractor": lambda p: extract_classification_text(p)
                }
            ]
        }
    ]
    
    # éå†æ‰€æœ‰å·¥å…·æ˜ å°„ï¼Œæ‰¾åˆ°åŒ¹é…çš„
    for mapping in tool_mappings:
        if any(keyword in prompt_lower for keyword in mapping["keywords"]):
            # è¿”å›ç¬¬ä¸€ä¸ªåŒ¹é…çš„å·¥å…·ï¼ˆå¯ä»¥æ ¹æ®éœ€è¦è°ƒæ•´é€»è¾‘ï¼‰
            tool_config = mapping["tools"][0]
            
            # å¦‚æœæœ‰å‚æ•°æå–å‡½æ•°ï¼Œä½¿ç”¨å®ƒæ¥æ›´æ–°å‚æ•°
            if "param_extractor" in tool_config:
                extracted_params = tool_config["param_extractor"](prompt)
                if extracted_params:
                    tool_config["params"].update(extracted_params)
            
            return tool_config
    
    return None

def extract_city_name(prompt):
    """ä»æ–‡æœ¬ä¸­æå–åŸå¸‚åç§°"""
    # ç®€å•çš„åŸå¸‚åæ˜ å°„
    city_mapping = {
        "åŒ—äº¬": "beijing", "ä¸Šæµ·": "shanghai", "å¹¿å·": "guangzhou", 
        "æ·±åœ³": "shenzhen", "æˆéƒ½": "chengdu", "æ­å·": "hangzhou",
        "é‡åº†": "chongqing", "æ­¦æ±‰": "wuhan", "è¥¿å®‰": "xian"
    }
    
    for chinese_name, pinyin_name in city_mapping.items():
        if chinese_name in prompt:
            return {"city_name": pinyin_name}
    
    # å¦‚æœæ²¡æœ‰åŒ¹é…çš„ä¸­æ–‡åŸå¸‚åï¼Œå°è¯•æå–å¯èƒ½çš„æ‹¼éŸ³
    words = prompt.split()
    for word in words:
        if word.isalpha() and len(word) > 2:  # ç®€å•çš„æ‹¼éŸ³æ£€æµ‹
            return {"city_name": word.lower()}
    
    return {"city_name": "beijing"}  # é»˜è®¤è¿”å›åŒ—äº¬

def extract_currency_params(prompt):
    """æå–è´§å¸è½¬æ¢å‚æ•°"""
    import re
    
    # æå–é‡‘é¢
    money_match = re.search(r'(\d+(?:\.\d+)?)\s*(ç¾å…ƒ|ç¾é‡‘|usd)', prompt, re.IGNORECASE)
    if money_match:
        money = float(money_match.group(1))
        return {"money": money, "source_coin": "USD", "aim_coin": "CNY"}
    
    return {"money": 100, "source_coin": "USD", "aim_coin": "CNY"}  # é»˜è®¤å€¼

def extract_classification_text(prompt):
    """æå–éœ€è¦åˆ†ç±»çš„æ–‡æœ¬"""
    # å°è¯•ä»å¼•å·ä¸­æå–æ–‡æœ¬
    import re
    text_match = re.search(r'["â€œâ€]([^"â€œâ€]+)["â€œâ€]', prompt)
    if text_match:
        return {"text": text_match.group(1)}
    
    # å¦‚æœæ²¡æœ‰å¼•å·ï¼Œå°è¯•ä»"æ–‡æœ¬ï¼š"åé¢æå–
    if "æ–‡æœ¬ï¼š" in prompt:
        text = prompt.split("æ–‡æœ¬ï¼š")[1].strip()
        return {"text": text}
    
    # é»˜è®¤è¿”å›åŸæç¤ºè¯
    return {"text": prompt}

async def get_model_response(prompt, model_name, use_tool):
    async with MCPServerSse(
            name="SSE Python Server",
            params={
                "url": "http://localhost:8900/sse",
            },
            client_session_timeout_seconds=20
    )as mcp_server:
        
        if use_tool:
            # æ£€æµ‹åº”è¯¥è°ƒç”¨å“ªä¸ªå·¥å…·
            tool_config = detect_tool_and_params(prompt)
            
            if tool_config:
                try:
                    # ç›´æ¥è°ƒç”¨å·¥å…·
                    tool_result = await mcp_server.call_tool(
                        tool_config["name"], 
                        tool_config["params"]
                    )
                    
                    # æ ¼å¼åŒ–å·¥å…·è¿”å›ç»“æœ
                    if hasattr(tool_result, 'content') and tool_result.content:
                        # ä»å·¥å…·ç»“æœä¸­æå–æ–‡æœ¬å†…å®¹
                        content_parts = []
                        for content in tool_result.content:
                            if hasattr(content, 'text'):
                                content_parts.append(content.text)
                        
                        tool_response = "\n".join(content_parts) if content_parts else str(tool_result)
                    else:
                        tool_response = str(tool_result)
                    
                    # è¿”å›å·¥å…·è°ƒç”¨ç»“æœ
                    yield f"ğŸ”§ å·¥å…·è°ƒç”¨: {tool_config['name']}\n\n"
                    yield f"ğŸ“Š ç»“æœ: {tool_response}"
                    return
                    
                except Exception as e:
                    yield f"âŒ å·¥å…·è°ƒç”¨å¤±è´¥: {str(e)}\n\n"
                    # å·¥å…·è°ƒç”¨å¤±è´¥åå›é€€åˆ°æ™®é€šAIå¯¹è¯
            
            else:
                yield "âš ï¸ æœªæ‰¾åˆ°åŒ¹é…çš„å·¥å…·ï¼Œä½¿ç”¨AIå¯¹è¯æ¨¡å¼\n\n"

            external_client = AsyncOpenAI(
            api_key=key,
            base_url="https://dashscope.aliyuncs.com/compatible-mode/v1",
            )
            
            agent = Agent(
                name="Assistant",
                instructions="",
                mcp_servers=[mcp_server],
                model=OpenAIChatCompletionsModel(
                    model=model_name,
                    openai_client=external_client,
                )
            )
        else:
            agent = Agent(
                name="Assistant",
                instructions="",
                model=OpenAIChatCompletionsModel(
                    model=model_name,
                    openai_client=external_client,
                )
            )

        result = Runner.run_streamed(agent, input=prompt, session=session)
        async for event in result.stream_events():
            if event.type == "raw_response_event" and isinstance(event.data, ResponseTextDeltaEvent):
                yield event.data.delta


if len(key) > 1:
    if prompt := st.chat_input():
        st.session_state.messages.append({"role": "user", "content": prompt})
        with st.chat_message("user"):
            st.markdown(prompt)

        with st.chat_message("assistant"):
            message_placeholder = st.empty()
            full_response = ""

            with st.spinner("è¯·æ±‚ä¸­..."):
                try:
                    response_generator = get_model_response(prompt, model_name, use_tool)

                    async def stream_and_accumulate(generator):
                        accumulated_text = ""
                        async for chunk in generator:
                            accumulated_text += chunk
                            message_placeholder.markdown(accumulated_text + "â–Œ")
                        return accumulated_text

                    full_response = asyncio.run(stream_and_accumulate(response_generator))
                    message_placeholder.markdown(full_response)

                except Exception as e:
                    error_message = f"å‘ç”Ÿé”™è¯¯: {e}"
                    message_placeholder.error(error_message)
                    full_response = error_message
                    print(f"Error during streaming: {e}")

            # 4. å°†å®Œæ•´çš„åŠ©æ‰‹å›å¤æ·»åŠ åˆ° session state
            st.session_state.messages.append({"role": "assistant", "content": full_response})
