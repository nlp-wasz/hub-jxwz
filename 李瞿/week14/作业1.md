# 文档公式解析与智能问答系统方案对比

## 方案概述

### 方案一（solu1）：检索+大模型直接计算
- **公式处理方式**：
  - 先用 embedding（Qwen3-Embedding/BGE）对所有公式和文档内容做向量化
  - 对每个问题，检索出最相关的 topN（如8个）公式文本，拼接到 prompt 里

- **计算实现**：
  - 没有用代码自动解析公式，也没有用 sympy 或其他数学库做自动计算
  - 直接把问题和相关公式文本交给大模型（Qwen3-Thinking），让大模型"理解公式、选择合适公式、推理并计算"
  - 大模型输出结果，要求是数值（如 answer: "100"），但实际计算过程和公式选择都由大模型完成

- **优缺点**：
  - 优点：实现简单，依赖大模型的强推理能力，能处理复杂语义和公式选择
  - 缺点：极度依赖大模型，token消耗大，无法保证每次都能选对公式或计算准确，缺乏可控性和可解释性

### 方案二（solu2）：文档解析+本地模型生成答案
- **公式处理方式**：
  - 先用 PyPDFLoader/MarkdownLoader 批量解析 PDF/MD 文档，抽取文本和公式，保存为 CSV
  - 没有专门的公式结构化或代码生成，公式只是作为文本背景知识

- **计算实现**：
  - 用本地 Qwen2.5-7B（HuggingFace pipeline）逐条处理问题和背景知识
  - prompt 里明确要求"只回答一个数字或估计结果"，但实际计算还是交给大模型
  - 没有用 sympy 或其他数学库做公式代码解析和自动计算，所有推理和计算都由大模型完成

- **优缺点**：
  - 优点：流程分步，支持多格式文档，能批量处理问题，依赖本地大模型，成本低
  - 缺点：公式只是背景知识，无法自动解析和代码化，计算准确性依赖大模型，缺乏自动化公式推理和可解释性

### 方案三（solu3）：检索+公式结构化+sympy自动计算+大模型辅助
- **公式处理方式**：
  - 先用 embedding 检索相关文档，拼接 topK 文档内容作为上下文
  - prompt 设计非常详细，要求大模型输出结构化 JSON，包括"选中的公式、参数、猜测参数、意图、思考过程、最终答案"

- **计算实现**：
  - 大模型输出后，代码会自动解析 JSON，提取公式和参数
  - 如果意图是数值计算，代码会用 sympy（包括 latex 解析和普通表达式）自动执行公式计算，参数支持自动填充和类型安全
  - 只有在 sympy 计算失败时，才用大模型的原始答案兜底

- **优缺点**：
  - 优点：公式结构化、参数自动提取、自动代码计算，极大提升了可控性和可解释性。大模型只负责理解和结构化，计算交给 sympy，结果更可靠
  - 缺点：实现复杂，依赖大模型能正确输出结构化 JSON，公式和参数提取有时会失败，异常处理需要兜底

## 关键技术点对比

| 方案 | 公式结构化 | 公式代码生成 | 自动计算 | 大模型作用 | 可解释性 | 计算准确性 |
|------|------------|--------------|----------|------------|----------|------------|
| solu1 | 否 | 否 | 否 | 全部推理与计算 | 低 | 依赖大模型 |
| solu2 | 否 | 否 | 否 | 全部推理与计算 | 低 | 依赖大模型 |
| solu3 | 是 | 是 | 是（sympy） | 结构化理解+兜底 | 高 | 主要靠代码 |

## 总结

- **solu1/solu2**：公式只是文本，所有推理和计算都交给大模型，无法自动代码化和计算，结果可解释性差，准确性依赖大模型
- **solu3**：大模型负责结构化理解和公式/参数提取，代码自动完成公式计算（sympy），可解释性和准确性大幅提升，是最专业的方案