### 对多模态RAG的项目，如果用户使用【文本】提问 vs 【文本 + 图】提问，你会怎么处理？有什么区别？
    1、文本
        用户文本提问 → 文本理解 → 多模态检索 → 答案生成
        先进行意图识别、关键实体提取，使用 BGE 文本嵌入模型将问题转为向量，在Milvus中检索相关 chunk，
        将检索到的文本输入到 CLIP 中，生成答案

    2、文本 + 图
        用户文本+图像提问 → 多模态理解 → 跨模态检索 → 关联推理 → 答案生成
        同时分析文本和图像，使用 BGE 文本编码器将问题转为向量 ，使用 DeepSeek-OCR 进行图像识别，检索相关图表，
        在图像库中查找相似的图表进行比较分析，
        最后关联推理生成答案

#### 区别

|      | 文本提问     | 文本+图像提问            |
|------|----------|--------------------|
| 检索输入 | 文本向量     | 文本向量 + 图像向量        |
| 检索方法 | 单模态检索为主  | 跨模态检索              |
| 向量编码 | BGE文本编码器 | 多模态编码器             |
| 检索目标 | 相关文本段落   | 相关文本 + 相似图像 + 关联内容 |
| 响应时间 | 更快       | 稍慢，由图像复杂度决定        |
