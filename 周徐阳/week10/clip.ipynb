#%% md
# 中文 CLIP 模型图文匹配演示
使用 CPU 推理，10 张图片 + 10 个文本描述
#%%
import torch
import numpy as np
from PIL import Image
from transformers import ChineseCLIPProcessor, ChineseCLIPModel
from sklearn.preprocessing import normalize
import matplotlib.pyplot as plt
import requests
from io import BytesIO

# 强制使用 CPU
device = "cpu"
print(f"使用设备: {device}")
#%% md
## 1. 加载中文 CLIP 模型
#%%
# 从 ModelScope 加载中文 CLIP 模型
model_name = "AI-ModelScope/chinese-clip-vit-base-patch16"

print("正在加载模型...")
model = ChineseCLIPModel.from_pretrained(model_name)
processor = ChineseCLIPProcessor.from_pretrained(model_name)

# 设置为 CPU 模式
model = model.to(device)
model.eval()

print("模型加载完成！")
#%% md
## 2. 准备测试数据（10 张图片 + 10 个文本）
#%%
# 定义 10 个图片 URL（使用公开可访问的图片）
image_urls = [
    "https://picsum.photos/id/237/400/300",  # 狗
    "https://picsum.photos/id/10/400/300",   # 森林
    "https://picsum.photos/id/169/400/300",  # 山
    "https://picsum.photos/id/164/400/300",  # 海边
    "https://picsum.photos/id/180/400/300",  # 建筑
    "https://picsum.photos/id/292/400/300",  # 花
    "https://picsum.photos/id/65/400/300",   # 城市
    "https://picsum.photos/id/42/400/300",   # 道路
    "https://picsum.photos/id/82/400/300",   # 天空
    "https://picsum.photos/id/152/400/300",  # 湖泊
]

# 定义 10 个中文文本描述
text_descriptions = [
    "一只可爱的黑色小狗",
    "茂密的森林和树木",
    "雄伟的山峰和雪山",
    "美丽的海边风景",
    "现代化的建筑物",
    "鲜艳的花朵盛开",
    "繁华的城市街道",
    "笔直的公路和道路",
    "蔚蓝的天空和白云",
    "宁静的湖泊和水面",
]

print(f"准备了 {len(image_urls)} 张图片和 {len(text_descriptions)} 个文本描述")
#%% md
## 3. 加载图片
#%%
# 从 URL 加载图片
images = []

print("正在加载图片...")
for i, url in enumerate(image_urls):
    try:
        response = requests.get(url, timeout=10)
        img = Image.open(BytesIO(response.content)).convert('RGB')
        images.append(img)
        print(f"  加载图片 {i+1}/10 成功")
    except Exception as e:
        print(f"  加载图片 {i+1} 失败: {e}")
        # 创建一个空白图片作为替代
        images.append(Image.new('RGB', (400, 300), color='gray'))

print(f"\n成功加载 {len(images)} 张图片")
#%%
# 显示前 5 张图片
plt.figure(figsize=(15, 3))
for i in range(5):
    plt.subplot(1, 5, i+1)
    plt.imshow(images[i])
    plt.title(f"图片 {i+1}", fontsize=10)
    plt.axis('off')
plt.tight_layout()
plt.show()
#%% md
## 4. 图像特征提取（Image Encoding）
#%%
print("正在提取图像特征...")

# 处理所有图片
inputs = processor(images=images, return_tensors="pt", padding=True)
inputs = {k: v.to(device) for k, v in inputs.items()}

with torch.no_grad():
    image_features = model.get_image_features(**inputs)
    image_features = image_features.cpu().numpy()

# 归一化特征向量
image_features = normalize(image_features)

print(f"图像特征形状: {image_features.shape}")  # (10, 512)
#%% md
## 5. 文本特征提取（Text Encoding）
#%%
print("正在提取文本特征...")

# 处理所有文本
inputs = processor(text=text_descriptions, return_tensors="pt", padding=True)
inputs = {k: v.to(device) for k, v in inputs.items()}

with torch.no_grad():
    text_features = model.get_text_features(**inputs)
    text_features = text_features.cpu().numpy()

# 归一化特征向量
text_features = normalize(text_features)

print(f"文本特征形状: {text_features.shape}")  # (10, 512)
#%% md
## 6. 图文匹配：给定文本，找最匹配的图片
#%%
# 选择一个查询文本
query_text_idx = 0  # "一只可爱的黑色小狗"

print(f"查询文本: {text_descriptions[query_text_idx]}")
print("\n正在计算相似度...\n")

# 计算该文本与所有图片的相似度
similarity = np.dot(text_features[query_text_idx], image_features.T)

# 排序得到最相似的图片
top_indices = similarity.argsort()[::-1][:3]

print("Top 3 最匹配的图片：")
for rank, idx in enumerate(top_indices, 1):
    print(f"  {rank}. 图片 {idx+1}, 相似度: {similarity[idx]:.4f}")

# 可视化结果
plt.figure(figsize=(12, 4))
for i, idx in enumerate(top_indices):
    plt.subplot(1, 3, i+1)
    plt.imshow(images[idx])
    plt.title(f"排名 {i+1}\n相似度: {similarity[idx]:.4f}", fontsize=10)
    plt.axis('off')
plt.suptitle(f"查询文本: {text_descriptions[query_text_idx]}", fontsize=12, y=1.05)
plt.tight_layout()
plt.show()
#%% md
## 7. 图文匹配：给定图片，找最匹配的文本
#%%
# 选择一个查询图片
query_image_idx = 0

print("查询图片:")
plt.figure(figsize=(4, 3))
plt.imshow(images[query_image_idx])
plt.axis('off')
plt.show()

print("\n正在计算相似度...\n")

# 计算该图片与所有文本的相似度
similarity = np.dot(image_features[query_image_idx], text_features.T)

# 排序得到最相似的文本
top_indices = similarity.argsort()[::-1][:5]

print("Top 5 最匹配的文本描述：")
for rank, idx in enumerate(top_indices, 1):
    print(f"  {rank}. {text_descriptions[idx]} (相似度: {similarity[idx]:.4f})")
#%% md
## 8. 完整的图文相似度矩阵
#%%
# 计算所有图片和文本之间的相似度矩阵
similarity_matrix = np.dot(text_features, image_features.T)

print("图文相似度矩阵:")
print(f"形状: {similarity_matrix.shape} (10个文本 × 10张图片)\n")

# 可视化相似度矩阵
plt.figure(figsize=(12, 10))
plt.imshow(similarity_matrix, cmap='hot', interpolation='nearest')
plt.colorbar(label='相似度')
plt.xlabel('图片索引', fontsize=12)
plt.ylabel('文本索引', fontsize=12)
plt.title('图文相似度矩阵', fontsize=14, pad=20)

# 添加数值标注
for i in range(len(text_descriptions)):
    for j in range(len(images)):
        plt.text(j, i, f'{similarity_matrix[i, j]:.2f}',
                ha="center", va="center", color="white", fontsize=8)

plt.xticks(range(10), [f'图{i+1}' for i in range(10)])
plt.yticks(range(10), [f'文本{i+1}' for i in range(10)])
plt.tight_layout()
plt.show()

# 找出每个文本最匹配的图片
print("\n每个文本最匹配的图片：")
for i, text in enumerate(text_descriptions):
    best_match = similarity_matrix[i].argmax()
    score = similarity_matrix[i][best_match]
    print(f"  文本{i+1}: '{text}' → 图片{best_match+1} (相似度: {score:.4f})")
#%% md
## 9. 总结

本 notebook 演示了：
1. 从 ModelScope 加载中文 CLIP 模型
2. 使用 CPU 进行推理
3. 提取 10 张图片和 10 个文本的特征向量（512 维）
4. 计算图文相似度并进行匹配
5. 可视化匹配结果

你可以替换 `image_urls` 和 `text_descriptions` 来测试自己的数据！
