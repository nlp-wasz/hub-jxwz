

# 【作业2】对多模态RAG的项目，如果用户使用【文本】提问 vs 【文本 + 图】提问，你会怎么处理？有什么区别？

【文本】提问
    输入 ----》 转换为向量 ----》 向量相似度检索  ----》 大语言模型组装生成答案


【文本 + 图】提问
    方案一：类似deepseek，使用视觉模型将图片转换为详细的文本描述， 结合原有文本描述，统一使用文本方式 转换为向量进行 文本的多模态检索
    方案二：文本单独搜索、图片单独搜索，再融合两者结果？ 预期效果不怎么好
    方案三： 使用多模态大模型同时理解文本和图片，作为一个整体生成一个向量进行问答？ 暂时没有详细思路

主要区别在于 文本 + 图 的形式，需要考虑图的理解、文本和图的融合，以及检索的形式和结果的组装