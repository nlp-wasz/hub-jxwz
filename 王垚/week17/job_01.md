### 第一步：查询生成

使用 GPT-2 模型，输入格式如下：

```
Previously, the customer has bought:
<ITEM TITLE 1>. <ITEM TITLE 2>... <ITEM TITLE T-1>
In the future, the customer wants to buy
```

选用 117M 参数的 GPT-2，训练时用前 T-1 个物品标题预测第 T 个物品。这个想法基于一个假设：最精确的搜索查询就是目标物品的标题本身。

为捕获用户多方面兴趣，采用 beam search 生成多个查询（而不是单个）。给定 beam size m，每步保留 top-m 候选，最终生成 m 个不同查询。每个查询代表用户兴趣的一个方面，既保证相关性也保证多样性。

### 第二步：物品检索

使用 BM25 搜索引擎。BM25 考虑词频饱和度和文档长度归一化，通过 k1 和 b 参数可调。

多查询结果组合采用 ranking-based 策略：总推荐 K 个物品，生成 m 个查询，则从得分最高的查询取 top-K/m，依次从其他查询添加不重复的 top-K/m，直到凑够 K 个。这样平衡相关性和多样性，每个查询都有贡献。

### 第三步：训练策略

两步训练，实际应用中更友好，便于迭代。

**第一步：训练语言模型**
- 模型：GPT-2 (117M)
- 优化器：Adam with weight decay
- 学习率：0.0001
- Warm-up：2000 步
- Epochs：20

**第二步：优化搜索引擎**
- 方法：Grid search
- 参数：k1 ∈ [0, 3], b ∈ (0, 1)
- 目标：Recall@K

## 关键技术

**语言空间嵌入**：在语义空间而非 ID 空间学习表示，利用物品文本内容和预训练语言模型的表示能力。

**Multi-query beam search**：生成 m 个查询捕获多方面、不同粒度的兴趣。实验显示这提高了多样性和覆盖率。

**冷启动**：新物品只要有文本描述就能被检索，搜索在语言空间不依赖物品 ID，天然支持动态增长的物品库。

**可解释性**：生成的查询是用户兴趣的可读描述，可直接展示给用户。例如："根据您的观看历史，您可能喜欢动作片和科幻片"。

## 实验结果

使用 Amazon Review 5-core 数据集：
- **Beauty**：22,254 用户，11,778 物品，190,726 交互，平均序列长度 7.439
- **Electronics**：728,719 用户，159,456 物品，6,724,382 交互，平均序列长度 7.797

数据预处理：过滤缺失或超长标题（>400 字符），用户序列去重，最大长度截断为 15，按 0.8/0.1/0.1 划分训练/验证/测试集，测试集最后一个物品为预测目标。

**评估指标**：
- **Recall@K**：top-K 是否包含目标物品，K = 5, 10, 20, 40
- **Diversity@K**：推荐物品间的不相似度，Jaccard 相似度计算
- **Coverage@K**：推荐覆盖用户历史类别的程度，比 Diversity@K 更合理（Diversity 可能偏向随机推荐）

**性能提升**：
- Beauty：相对提升 75.7% (vs BERT4Rec, Recall@40)
- Electronics：相对提升 22.2% (vs BERT4Rec, Recall@40)

**基线对比**：
- FM-BPR：协同过滤 + BPR
- ContentRec：bag-of-words + mean-pooling
- YouTubeDNN：深度神经网络
- BERT4Rec：BERT 双向自注意力

BERT4Rec 用了现代语言建模但把物品当 ID，内容信息丢失。ContentRec 用了内容但 bag-of-words 表示能力不足。GPT4Rec 结合了两者优势。

**多查询效果**：
- 生成 K 个查询检索 K 个物品效果最好（每查询检索 1 个物品）
- 单调递增：K 增加、查询数增加，Recall@K 都提升
- Diversity@K 和 Coverage@K 也是生成 K 个查询时最高
- 单纯增加 K 不增加查询数不会提高多样性，搜索本身对多样性帮助不大

**案例**：
1. Beauty 用户（多类别多品牌）：查询覆盖历史品牌并生成 "makeup palette" 等新关联，能捕获物品间语义关联
2. Electronics 用户（专注罗技无线鼠标）：查询集中在同品牌同类别但产品细节不同，能适应不同多样性水平
