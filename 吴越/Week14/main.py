import os

os.environ["OPENAI_AI_KEY"]="sk-65b8e3a30263430f99da2cc286004704"
os.environ["OPENAI_BASE_URL"]="https://dashscope.aliyuncs.com/compatible-mode/v1"
from agents import Agent,Runner
from agents.mcp.server import MCPServerSse
from agents.mcp import MCPServer,ToolFilterStatic
from agents import set_default_openai_api, set_tracing_disabled
from tool_selector import Tool_Selector
from langchain_core.prompts import PromptTemplate

set_default_openai_api("chat_completions")
set_tracing_disabled(True)

async def qa(query,topk):
    template = '''
       ä½ æ˜¯ä¸“ä¸šçš„AIè®¡ç®—åŠ©æ‰‹ï¼Œè´Ÿè´£ä½¿ç”¨ç»™å®šçš„å·¥å…·é›†è§£å†³ç”¨æˆ·é—®é¢˜ã€‚ä½ å·²ç»è¿æ¥äº†ç‰¹å®šçš„è®¡ç®—å·¥å…·ï¼Œè¿™äº›å·¥å…·æ˜¯æ ¹æ®ä½ çš„é—®é¢˜è‡ªåŠ¨ç­›é€‰å‡ºæ¥çš„æœ€ç›¸å…³å·¥å…·ã€‚ä½ å¯ä»¥ç›´æ¥ä½¿ç”¨è¿™äº›å·¥å…·è¿›è¡Œè®¡ç®—ã€‚
        # ğŸ“‹ å·¥ä½œæµç¨‹
        1. **åˆ†æéœ€æ±‚**ï¼šä»”ç»†ç†è§£ç”¨æˆ·çš„è®¡ç®—éœ€æ±‚
        2. **é€‰æ‹©å·¥å…·**ï¼šä»å½“å‰å¯ç”¨å·¥å…·ä¸­é€‰æ‹©æœ€é€‚åˆçš„ä¸€ä¸ª
        3. **ç¡®è®¤å‚æ•°**ï¼šå¦‚æœ‰ç¼ºå¤±å‚æ•°ï¼Œè¯·ç”¨æˆ·æä¾›
        4. **æ‰§è¡Œè®¡ç®—**ï¼šè°ƒç”¨å·¥å…·è¿›è¡Œè®¡ç®—
        5. **è§£é‡Šç»“æœ**ï¼šæ¸…æ™°åœ°å±•ç¤ºå¹¶è§£é‡Šè®¡ç®—ç»“æœ
       é—®é¢˜ï¼š{query}
       '''

    prompt = PromptTemplate(
        template=template,
        input_variables=["query"])
    tools=Tool_Selector().get_similarity_tool(query,topk)
    tool_mcp_tools_filter: ToolFilterStatic = ToolFilterStatic(allowed_tool_names=tools)
    async with MCPServerSse(
        name="MCPServerSse",
        params={"url": "http://localhost:8900/sse"},
        cache_tools_list=False,
        tool_filter=tool_mcp_tools_filter,
        client_session_timeout_seconds=20,
    ) as server:
        agent=Agent(
            model="Qwen3-235B-A22B-Thinking-2507",
            name="Assistant",
            instructions=prompt
        )

        result = Runner.run_streamed(agent, input=query)
        return result.final_output