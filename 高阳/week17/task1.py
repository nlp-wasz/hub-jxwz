1、数据准备与格式化
输入数据为用户的历史物品交互序列。将这些交互物品的标题与一个特定的提示词模板组合，形成语言模型的输入文本。

2、模型选择与微调：采用预训练的GPT-2语言模型，并使用上述格式化后的用户序列数据对其进行微调。为了捕捉用户多样化的兴趣并提高推荐结果的多样性，采用了集束搜索（Beam Search）技术来生成多个查询。

3、物品检索，将上一步生成的每个查询，输入到一个搜索引擎中，搜索引擎使用匹配函数来检索语料库中最相关的物品。为了平衡相关性和多样性，提出了一种基于排名的策略来合并来自不同查询的搜索结果：首先，从生成得分最高的查询的搜索结果中，检索出前 K/m 个物品（K 为推荐总数，m 为查询数）；然后，依次从其余查询的搜索结果中，按得分排名添加 K/m 个不重复的物品。

4、训练策略：采用灵活的两步训练流程，分别优化语言模型和搜索引擎：
语言模型训练：对于每个用户的交互序列 i1, i2, ..., iT，使用前 T-1 个物品标题构建提示词，并将其与最后一个物品 iT 的标题拼接，作为训练语料来微调GPT-2。
搜索引擎优化：在语言模型训练完成后，通过网格搜索BM25的参数（k1 和 b），以在搜索生成查询来检索目标物品时获得最佳性能。

5、 实验验证
数据集：在Amazon Review数据的Beauty和Electronics两个公开数据集上进行实验。
评估指标：主要使用Recall@K，同时关注Diversity@K和Coverage@K来衡量多样性和用户多兴趣的覆盖度。
基线对比：与FM-BPR、ContentRec、YouTubeDNN、BERT4Rec等基线方法对比。
